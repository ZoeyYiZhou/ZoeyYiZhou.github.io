<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8"/>

<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
<link rel="stylesheet" href="base.min.css"/>
<link rel="stylesheet" href="fancy.min.css"/>
<link rel="stylesheet" href="main.css"/>
<script src="compatibility.min.js"></script>
<script src="theViewer.min.js"></script>
<script>
try{
theViewer.defaultViewer = new theViewer.Viewer({});
}catch(e){}
</script>
<title></title>
</head>
<body>
<div id="sidebar">
<div id="outline">
</div>
</div>
<div id="page-container">
<div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg1.png"/><div class="c x1 y1 w2 h2"><div class="t m0 x2 h3 y2 ff1 fs0 fc0 sc0 ls0 ws0">!</div><div class="t m0 x3 h4 y3 ff2 fs1 fc0 sc0 ls1 ws0">207$PROGECT<span class="fs2 ls0">$</span></div><div class="t m0 x4 h5 y4 ff1 fs3 fc0 sc0 ls2 ws0">Survival!of!House!Sparr<span class="_ _0"></span>ows<span class="ls0">!</span></div><div class="t m0 x5 h3 y5 ff1 fs0 fc0 sc0 ls3 ws0">Yi!Zhou<span class="ls0">!</span></div><div class="t m0 x6 h3 y6 ff1 fs0 fc0 sc0 ls4 ws0">(99808608 4) <span class="ls0">!</span></div><div class="t m0 x7 h3 y7 ff1 fs0 fc0 sc0 ls3 ws0">YanLin!Li<span class="ls0">!</span></div><div class="t m0 x6 h3 y8 ff1 fs0 fc0 sc0 ls4 ws0">(99830330 1) <span class="ls0">!</span></div><div class="t m0 x8 h6 y9 ff3 fs4 fc1 sc0 ls0 ws0"> <span class="_ _1"> </span> </div></div><div class="c x9 ya w3 h7"><div class="t m0 xa h5 yb ff1 fs3 fc0 sc0 ls5 ws0">MARC<span class="_ _0"></span>H!<span class="_ _0"></span>22,!<span class="_ _0"></span>2017<span class="ls0">!</span></div></div><div class="c x1 y1 w2 h2"><div class="t m0 xb h3 yc ff1 fs0 fc0 sc0 ls6 ws0">!!!!!<span class="_ _2"></span><span class="ls0">!</span></div></div><div class="c x9 ya w3 h7"><div class="t m0 xc h3 yd ff1 fs0 fc0 sc0 ls6 ws0">!!!!!<span class="_ _2"></span><span class="ls0">!</span></div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf2" class="pf w0 h0" data-page-no="2"><div class="pc pc2 w0 h0"><img class="bi xd ye w4 h8" alt="" src="bg2.png"/><div class="c x1 y1 w2 h2"><div class="t m0 xe h9 yf ff3 fs5 fc1 sc0 ls7 ws0">Survival of<span class="_ _0"></span> House Sparro<span class="_ _0"></span>ws<span class="ls0"> </span></div><div class="t m0 xb h6 y10 ff3 fs4 fc1 sc0 ls0 ws0"> </div><div class="t m0 xf h6 y11 ff3 fs4 fc1 sc0 ls8 ws0">Abstract<span class="ls0"> </span></div><div class="t m0 x10 ha y12 ff4 fs6 fc1 sc0 ls0 ws0">The data recorded various physical characteristics of house sparrows which were found </div><div class="t m0 x8 ha y13 ff4 fs6 fc1 sc0 ls0 ws0">on the ground after a severe winter storm in 1898. Among these house sparrows, some survived </div><div class="t m0 x8 ha y14 ff4 fs6 fc1 sc0 ls0 ws0">and some perished. We are interested in the relationship between the probability of survival and </div><div class="t m0 x8 ha y15 ff4 fs6 fc1 sc0 ls0 ws0">sparrows’ physical characteristics.  </div><div class="t m0 x10 ha y16 ff4 fs6 fc1 sc0 ls0 ws0">Our final model suggests that the survival of sparrows is found to be negative related to </div><div class="t m0 x8 ha y17 ff4 fs6 fc1 sc0 ls0 ws0">total length and weight, but positive related to length of humerus, length of keel of sternum, and </div><div class="t m0 x8 ha y18 ff4 fs6 fc1 sc0 ls0 ws0">square of femur length. We conclude sparrows with lower body weight, and larger body bone </div><div class="t m0 x8 ha y19 ff4 fs6 fc1 sc0 ls0 ws0">including longer humerus, femur and keel of sternum <span class="ls9">len</span>gths tend to survive. </div><div class="t m0 x8 hb y1a ff4 fs4 fc2 sc0 ls0 ws0"> </div><div class="t m0 x11 h6 y1b ff3 fs4 fc1 sc0 lsa ws0">Introduction<span class="ls0"> </span></div><div class="t m0 x10 ha y1c ff4 fs6 fc1 sc0 ls0 ws0">Usually, people consider sparrows with larger body size tend to survival. Some studies </div><div class="t m0 x8 ha y1d ff4 fs6 fc1 sc0 ls0 ws0">have found that survival rate increased significantly with greater general size, including longer </div><div class="t m0 x8 ha y1e ff4 fs6 fc1 sc0 ls0 ws0">humerus, femur and keel of sternum lengths and wider skulls. <span class="fc3">Zoologist</span><span class="lsb">s <span class="ls9">also</span></span> found that </div><div class="t m0 x8 ha y1f ff4 fs6 fc1 sc0 ls0 ws0">sparrows with lower body weight and shorter total length have more probability to survive.  </div><div class="t m0 x10 ha y20 ff4 fs6 fc1 sc0 ls0 ws0">In this report, we are interested in how these physical characteristics of house sparrows </div><div class="t m0 x8 ha y21 ff4 fs6 fc1 sc0 ls0 ws0">influence their survival status during winter, and want to see if our conclusion support or </div><div class="t m0 x8 ha y22 ff4 fs6 fc1 sc0 ls0 ws0">disagree with these scientific findings. Since the response variable is binary, we use logistic </div><div class="t m0 x8 ha y23 ff4 fs6 fc1 sc0 ls0 ws0">regression model to fit the data.  </div><div class="t m0 x8 ha y24 ff4 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x12 h6 y25 ff3 fs4 fc1 sc0 ls8 ws0">Data Processing<span class="ls0"> </span></div><div class="t m0 x10 ha y26 ff4 fs6 fc1 sc0 ls0 ws0">The dataset is pretty clear, and does not have ‘<span class="lsb">NA</span>’ or missing values. It consists two </div><div class="t m0 x8 ha y27 ff4 fs6 fc1 sc0 ls0 ws0">qualitative variables including the response variable, and 9 quantitative variables. Looking at the </div><div class="t m0 x8 ha y28 ff4 fs6 fc1 sc0 ls0 ws0">scatter plot matrix of 9 quantitative variables (Figure 1), there are no obvious outlier in the plot, </div><div class="t m0 x8 ha y29 ff4 fs6 fc1 sc0 ls0 ws0">but some first order multicollinearity are discerned among some variables. Figure 2 shows the </div><div class="t m0 x8 ha y2a ff4 fs6 fc1 sc0 ls0 ws0">multicollinearity more explicitly:  We can see that alar extent, length of humerus, length of </div><div class="t m0 x8 ha y2b ff4 fs6 fc1 sc0 ls0 ws0">femur, and length tibio-tarsus have high multicollinearity to each other. This make sense, as </div><div class="t m0 x8 ha y2c ff4 fs6 fc1 sc0 ls0 ws0">larger sparrows tend to have longer length in wings and bones at the same time.  </div><div class="t m0 x10 ha y2d ff4 fs6 fc1 sc0 ls0 ws0">Histograms (Figure 3) are performed on the 9 quantitative variables. Most of the </div><div class="t m0 x8 ha y2e ff4 fs6 fc1 sc0 ls0 ws0">histograms appear to be normal, whereas the Weight variable <span class="ls9">is</span> left skewed and the Beak <span class="lsb">Head</span> </div><div class="t m0 x8 ha y2f ff4 fs6 fc1 sc0 ls0 ws0">Length <span class="ls9">is</span> right skewed. Therefore, we perform log transformation on these two variables. Since </div><div class="t m0 x8 ha y30 ff4 fs6 fc1 sc0 ls0 ws0">the quantitative variables are measured in different scales, we also standardize all the quantitative </div><div class="t m0 x8 ha y31 ff4 fs6 fc1 sc0 ls0 ws0">variables, and plot the histogram of them again (Figure 4). All the histograms looks normal and </div><div class="t m0 x8 ha y32 ff4 fs6 fc1 sc0 ls0 ws0">centered at zero. We also fit a lowess fit line for response variable against the 9 quantitative </div><div class="t m0 x8 ha y33 ff4 fs6 fc1 sc0 ls0 ws0">variables (Figure 5). Most of the lowess line in the plots are linear, so it is reasonable to fit the </div><div class="t m0 x8 ha y34 ff4 fs6 fc1 sc0 ls0 ws0">initial model with first order variables. </div><div class="t m0 x8 hc y35 ff3 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x13 hc y36 ff3 fs6 fc1 sc0 ls0 ws0">Model Selection </div><div class="t m0 x8 ha y37 ff4 fs6 fc1 sc0 ls0 ws0">In this part, we use forward stepwise procedure based on both AIC and BIC criterion, and then </div><div class="t m0 x8 ha y38 ff4 fs6 fc1 sc0 ls0 ws0">fit the model with second order and interaction term. </div><div class="t m0 x9 hc y39 ff3 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x9 hc y3a ff3 fs6 fc1 sc0 ls0 ws0">1.<span class="ff5"> <span class="_ _3"> </span></span><span class="ls9">First</span>-order model selection </div><div class="t m0 x10 ha y3b ff4 fs6 fc1 sc0 ls0 ws0">We fit the model with all first-order effects as our model 1. Our full model is  </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf3" class="pf w0 h0" data-page-no="3"><div class="pc pc3 w0 h0"><img class="bi x14 y3c w5 hd" alt="" src="bg3.png"/><div class="c x1 y1 w2 h2"><div class="t m0 x8 ha y3d ff4 fs6 fc1 sc0 ls0 ws0">logit(Status)  =  <span class="ff6">b</span></div><div class="t m0 x15 he y3e ff4 fs7 fc1 sc0 lsc ws0">0 </div><div class="t m0 x16 ha y3d ff4 fs6 fc1 sc0 ls0 ws0">+  <span class="ff6">b</span></div><div class="t m0 x17 he y3e ff4 fs7 fc1 sc0 ls0 ws0">1</div><div class="t m0 x18 ha y3d ff4 fs6 fc1 sc0 ls0 ws0">Age  +  <span class="ff6">b</span></div><div class="t m0 x19 he y3e ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x1a ha y3d ff4 fs6 fc1 sc0 ls0 ws0">TotalL  +  <span class="ff6">b</span></div><div class="t m0 x1b he y3e ff4 fs7 fc1 sc0 ls0 ws0">3</div><div class="t m0 x1c ha y3d ff4 fs6 fc1 sc0 ls0 ws0">AlarExtL+  <span class="ff6">b</span></div><div class="t m0 x1d he y3e ff4 fs7 fc1 sc0 ls0 ws0">4</div><div class="t m0 x1e ha y3d ff4 fs6 fc1 sc0 ls0 ws0">log(Wght)  +  <span class="ff6">b</span></div><div class="t m0 x1f he y3e ff4 fs7 fc1 sc0 ls0 ws0">5</div><div class="t m0 x20 ha y3d ff4 fs6 fc1 sc0 ls0 ws0">log(BeakHeadL)  + </div><div class="t m0 x8 hf y3f ff6 fs6 fc1 sc0 ls0 ws0">b</div><div class="t m0 x21 he y40 ff4 fs7 fc1 sc0 ls0 ws0">6</div><div class="t m0 x22 ha y3f ff4 fs6 fc1 sc0 ls0 ws0">HumerusL+ <span class="_ _4"></span><span class="ff6">b</span></div><div class="t m0 x23 he y40 ff4 fs7 fc1 sc0 ls0 ws0">7</div><div class="t m0 x24 ha y3f ff4 fs6 fc1 sc0 ls0 ws0">FemurL+ <span class="_ _4"></span><span class="ff6">b</span></div><div class="t m0 x25 he y40 ff4 fs7 fc1 sc0 ls0 ws0">8</div><div class="t m0 x26 ha y3f ff4 fs6 fc1 sc0 ls0 ws0">TribioTarsusL <span class="_ _4"></span>+ <span class="_ _4"></span> <span class="_ _4"></span><span class="ff6">b</span></div><div class="t m0 x27 he y40 ff4 fs7 fc1 sc0 ls0 ws0">9</div><div class="t m0 x28 ha y3f ff4 fs6 fc1 sc0 ls0 ws0">SkullWd <span class="_ _4"></span>+ <span class="_ _4"></span> <span class="_ _4"></span><span class="ff6">b</span></div><div class="t m0 x29 he y40 ff4 fs7 fc1 sc0 lsc ws0">10</div><div class="t m0 xd ha y3f ff4 fs6 fc1 sc0 lsb ws0">KeelL<span class="ls0"> <span class="_ _4"></span>and <span class="_ _4"></span>the <span class="_ _4"></span>empty <span class="_ _4"></span>model <span class="_ _4"></span>is </span></div><div class="t m0 x8 ha y41 ff4 fs6 fc1 sc0 ls0 ws0">logit(Status) <span class="_ _5"> </span>= <span class="_ _5"> </span><span class="ff6">b</span></div><div class="t m0 x24 he y42 ff4 fs7 fc1 sc0 lsc ws0">0. </div><div class="t m0 x16 ha y41 ff4 fs6 fc1 sc0 ls0 ws0">Both <span class="_ _5"> </span>forward <span class="_ _5"> </span>selection <span class="_ _5"> </span>or <span class="_ _5"> </span>backward <span class="_ _5"> </span>selection <span class="_ _5"> </span>with <span class="_ _5"> </span>AIC <span class="_ _5"> </span>and <span class="_ _5"> </span>BIC <span class="_ _5"> </span>criterion </div><div class="t m0 x8 ha y43 ff4 fs6 fc1 sc0 ls0 ws0">converges to the <span class="lsb">same</span> model (the summary <span class="_ _0"></span>and ANOVA table of this model is in <span class="_ _0"></span>figure 6 and 7)<span class="ls9">: </span> </div><div class="t m0 x8 ha y44 ff4 fs6 fc1 sc0 ls0 ws0">logit(Status) = 0.6335 - 2.0292*TotalL - 1.0690*<span class="ls9">ln</span>(Wght) + 1.6133 HumerusL + 0.9245*<span class="lsb">KeelL</span> </div><div class="t m0 x8 ha y45 ff4 fs6 fc1 sc0 ls0 ws0">with AIC: 79.73. </div><div class="t m0 x2a ha y46 ff4 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x8 ha y47 ff4 fs6 fc1 sc0 ls0 ws0">Above is the ANOVA table for the resulting best model. We can use Wald Test to test single <span class="ff6">b</span>. </div><div class="t m0 x8 ha y48 ff4 fs6 fc1 sc0 ls0 ws0">Ho: <span class="ff6">b</span></div><div class="t m0 x2b he y49 ff4 fs7 fc1 sc0 ls0 ws0">k</div><div class="t m0 x2c ha y48 ff4 fs6 fc1 sc0 ls0 ws0"> = 0 v.s. H</div><div class="t m0 x2d he y49 ff4 fs7 fc1 sc0 ls0 ws0">1</div><div class="t m0 x2e ha y48 ff4 fs6 fc1 sc0 ls9 ws0">: <span class="ff6 ls0">b</span></div><div class="t m0 x2f he y49 ff4 fs7 fc1 sc0 ls0 ws0">k</div><div class="t m0 x30 h10 y48 ff4 fs6 fc1 sc0 ls0 ws0"> <span class="ff7">!</span> 0 (k = 0…4) </div><div class="t m0 x8 ha y4a ff4 fs6 fc1 sc0 ls0 ws0">Z* = b</div><div class="t m0 x2c he y4b ff4 fs7 fc1 sc0 ls0 ws0">k</div><div class="t m0 x10 ha y4a ff4 fs6 fc1 sc0 ls9 ws0">/s{<span class="ls0"> b</span></div><div class="t m0 x31 he y4b ff4 fs7 fc1 sc0 ls0 ws0">k</div><div class="t m0 x32 ha y4a ff4 fs6 fc1 sc0 ls0 ws0"> } </div><div class="t m0 x8 ha y4c ff4 fs6 fc1 sc0 lsb ws0">All<span class="ls0"> the p-values of the x variables are smaller than <span class="ff6">a</span> = 0.05, so we fail to reject H</span></div><div class="t m0 x33 he y4d ff4 fs7 fc1 sc0 ls0 ws0">0<span class="lsd">, </span></div><div class="t m0 x34 ha y4c ff4 fs6 fc1 sc0 ls0 ws0">indicating </div><div class="t m0 x8 ha y1e ff4 fs6 fc1 sc0 ls0 ws0">none can be drop individually from the model. </div><div class="t m0 x10 ha y1f ff4 fs6 fc1 sc0 ls9 ws0">We <span class="ls0">also compare this model with the saturated model (ANOVA model is in the figure 8): </span></div><div class="t m0 x8 ha y20 ff4 fs6 fc1 sc0 ls0 ws0">Ho: logit(Status)=0.6335-2.0292*TotalL-1.0690*log(Wght) +1.6133 HumerusL+0.9245*<span class="lsb">KeelL</span>   </div><div class="t m0 x8 ha y21 ff4 fs6 fc1 sc0 ls0 ws0">H1: The model is not a good fit. </div><div class="t m0 x8 ha y22 ff4 fs6 fc1 sc0 ls0 ws0">G</div><div class="t m0 x35 he y4e ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x36 ha y22 ff4 fs6 fc1 sc0 ls0 ws0"> = -2[logL(R) – logL(F)] = 69.728 – 65.698 = 0.03 </div><div class="t m0 x8 ha y23 ff4 fs6 fc1 sc0 ls0 ws0">(G</div><div class="t m0 x36 he y4f ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x0 ha y23 ff4 fs6 fc1 sc0 ls0 ws0">: Residual Deviance of Reduced model - the Residual Deviance of the full model) </div><div class="t m0 x8 hf y50 ff6 fs6 fc1 sc0 ls0 ws0">c</div><div class="t m0 x21 he y51 ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x22 ha y50 ff4 fs6 fc1 sc0 ls0 ws0"> (1-0.05, 82-76) = <span class="ff6">c</span></div><div class="t m0 x37 he y51 ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x38 ha y50 ff4 fs6 fc1 sc0 ls0 ws0"> (0.95, 6) = 12.6 </div><div class="t m0 x8 ha y52 ff4 fs6 fc1 sc0 ls0 ws0">Since G</div><div class="t m0 x39 he y53 ff4 fs7 fc1 sc0 lsc ws0">2 </div><div class="t m0 x3a ha y52 ff4 fs6 fc1 sc0 ls0 ws0">is much smaller than <span class="ff6">c</span></div><div class="t m0 x3b he y53 ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x4 ha y52 ff4 fs6 fc1 sc0 ls0 ws0"> (0.95, 6) = 12.6, we fail to reject the null hypothesis. The model </div><div class="t m0 x8 ha y54 ff4 fs6 fc1 sc0 ls0 ws0">logit(Status)=0.6335-2.0292*TotalL-1.0690*<span class="ls9">ln</span>(Wght) <span class="_ _6"> </span>+1.6133 <span class="_ _6"> </span>HumerusL+0.9245*<span class="lsb">Keel</span>L <span class="_ _6"> </span><span class="ls9">is <span class="_ _6"> </span>a </span></div><div class="t m0 x8 ha y55 ff4 fs6 fc1 sc0 ls0 ws0">good fit of the sparrow data. </div><div class="t m0 x8 ha y56 ff4 fs6 fc1 sc0 ls0 ws0">   </div><div class="t m0 x9 hc y57 ff3 fs6 fc1 sc0 ls0 ws0">2.<span class="ff5"> <span class="_ _3"> </span></span>Second-order model selection </div><div class="t m0 x10 ha y58 ff4 fs6 fc1 sc0 ls0 ws0">We fit the full model with all first order and second order without interaction terms<span class="ls9">: </span> </div><div class="t m0 x8 ha y59 ff4 fs6 fc1 sc0 ls0 ws0">logit(Status) = <span class="ff6">b</span></div><div class="t m0 x23 he y5a ff4 fs7 fc1 sc0 lsc ws0">0 </div><div class="t m0 x15 ha y59 ff4 fs6 fc1 sc0 ls0 ws0">+ <span class="ff6">b</span></div><div class="t m0 x3c he y5a ff4 fs7 fc1 sc0 ls0 ws0">1</div><div class="t m0 x37 ha y59 ff4 fs6 fc1 sc0 ls0 ws0">Age + <span class="ff6">b</span></div><div class="t m0 x3d he y5a ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x3e ha y59 ff4 fs6 fc1 sc0 ls0 ws0">TotalL +…..+<span class="ff6">b</span></div><div class="t m0 x1b he y5a ff4 fs7 fc1 sc0 lsc ws0">10</div><div class="t m0 x3f ha y59 ff4 fs6 fc1 sc0 lsb ws0">KeelL<span class="ls0">+ <span class="ff6">b</span></span></div><div class="t m0 x40 he y5a ff4 fs7 fc1 sc0 lsc ws0">11</div><div class="t m0 x41 ha y59 ff4 fs6 fc1 sc0 ls0 ws0">Total</div><div class="t m0 x29 he y5b ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x42 ha y59 ff4 fs6 fc1 sc0 ls0 ws0">+<span class="ff6">b</span></div><div class="t m0 x43 he y5a ff4 fs7 fc1 sc0 lsc ws0">11</div><div class="t m0 x44 ha y59 ff4 fs6 fc1 sc0 ls0 ws0">AlarExtL</div><div class="t m0 x45 he y5b ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x46 ha y59 ff4 fs6 fc1 sc0 ls0 ws0">+….+<span class="ff6">b</span></div><div class="t m0 x47 he y5a ff4 fs7 fc1 sc0 lsc ws0">20</div><div class="t m0 x48 ha y59 ff4 fs6 fc1 sc0 ls0 ws0"> <span class="lsb">KeelL</span></div><div class="t m0 x49 he y5b ff4 fs7 fc1 sc0 ls0 ws0"> 2</div><div class="t m0 x4a ha y59 ff4 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x8 ha y5c ff4 fs6 fc1 sc0 ls0 ws0">and <span class="_ _2"></span>the empty <span class="_ _2"></span>model is <span class="_ _2"></span>logit(Status) <span class="_ _2"></span>= <span class="ff6">b</span></div><div class="t m0 x4b he y5d ff4 fs7 fc1 sc0 lsc ws0">0. </div><div class="t m0 x4c ha y5c ff4 fs6 fc1 sc0 ls0 ws0">Here <span class="_ _2"></span>all the <span class="_ _2"></span>x quantitative <span class="_ _2"></span>variables are <span class="_ _2"></span>set <span class="_ _2"></span>as centered </div><div class="t m0 x8 h10 y5e ff4 fs6 fc1 sc0 ls0 ws0">x = x -<span class="ff7">&quot;#<span class="_ _2"></span></span> . Since the full model has lots of <span class="_ _2"></span>variables and some variables are highly correlated with </div><div class="t m0 x8 ha y5f ff4 fs6 fc1 sc0 ls0 ws0">each <span class="_ _2"></span>other <span class="_ _2"></span>as <span class="_ _2"></span>we explained <span class="_ _2"></span>in <span class="_ _2"></span>the <span class="_ _2"></span>Data <span class="_ _2"></span>Processing <span class="_ _2"></span>section, using <span class="_ _2"></span>forward <span class="_ _2"></span>selection <span class="_ _2"></span>will <span class="_ _2"></span>be <span class="_ _2"></span>better </div><div class="t m0 x8 ha y60 ff4 fs6 fc1 sc0 ls0 ws0">than <span class="_ _7"></span>backward <span class="_ _7"></span>selection <span class="_ _7"></span>in <span class="_ _7"></span>this <span class="_ _7"></span>situation. <span class="_ _7"></span>Forward <span class="_ _7"></span>selection <span class="_ _7"></span>method <span class="_ _7"></span>can <span class="_ _7"></span>deal <span class="_ _7"></span>with <span class="_ _7"></span>multicollinearity </div><div class="t m0 x8 ha y61 ff4 fs6 fc1 sc0 ls0 ws0">better <span class="_ _8"> </span>compared <span class="_ _8"> </span>with <span class="_ _8"> </span>backward <span class="_ _8"> </span>selection, <span class="_ _8"> </span>and <span class="_ _8"> </span>it <span class="_ _8"> </span>will <span class="_ _8"> </span>drop <span class="_ _8"> </span>the <span class="_ _8"> </span>highly <span class="_ _8"> </span>correlated <span class="_ _8"> </span>variable </div><div class="t m0 x8 ha y62 ff4 fs6 fc1 sc0 ls0 ws0">automatically. By using forward selection with AIC and BIC, we get the selected model as: </div><div class="t m0 x8 ha y63 ff4 fs6 fc1 sc0 ls0 ws0">logit(Status) = TotalL + HumerusL + <span class="ls9">ln</span>(Wght) + KeelL + FemurL</div><div class="t m0 x4d he y64 ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x4e ha y63 ff4 fs6 fc1 sc0 ls0 ws0"> + BeakHeadL + HumerusL</div><div class="t m0 x4f he y64 ff4 fs7 fc1 sc0 ls0 ws0">2 </div><div class="t m0 x10 ha y65 ff4 fs6 fc1 sc0 ls0 ws0">After we have the best model <span class="_ _2"></span>chosen by forward selection method, we then set this <span class="_ _2"></span>model </div><div class="t m0 x8 ha y66 ff4 fs6 fc1 sc0 ls0 ws0">as <span class="_ _2"></span>a <span class="_ _2"></span>new <span class="_ _4"></span>full <span class="_ _2"></span>model, <span class="_ _2"></span>and <span class="_ _2"></span>put <span class="_ _4"></span>it <span class="_ _2"></span>into <span class="_ _2"></span>backward <span class="_ _2"></span>selection. <span class="_ _2"></span>This <span class="_ _4"></span>method <span class="_ _2"></span>can <span class="_ _2"></span>give <span class="_ _2"></span>us <span class="_ _4"></span>a <span class="_ _2"></span>better <span class="_ _2"></span>model </div><div class="t m0 x8 ha y67 ff4 fs6 fc1 sc0 ls0 ws0">compared with only fitting forward <span class="_ _2"></span>selection method. The final model for second-order model <span class="_ _2"></span>by </div><div class="t m0 x8 ha y68 ff4 fs6 fc1 sc0 ls0 ws0">both <span class="_ _7"></span>AIC and <span class="_ _7"></span>BIC <span class="_ _7"></span>is: logit(Status)=0.1472-2.2760*TotalL+ <span class="_ _7"></span>2.0814*HumerusL <span class="_ _7"></span>-1.1443*<span class="ls9">ln</span>(Wght) </div><div class="t m0 x8 ha y69 ff4 fs6 fc1 sc0 ls0 ws0">+ <span class="_ _2"></span>0.9354*KeelL <span class="_ _9"></span>+ <span class="_ _2"></span>0.5426*FemurL</div><div class="t m0 x50 he y6a ff4 fs7 fc1 sc0 lsc ws0">2 </div><div class="t m0 x51 ha y69 ff4 fs6 fc1 sc0 ls0 ws0">with <span class="_ _2"></span>AIC <span class="_ _9"></span>= <span class="_ _2"></span>77.22 <span class="_ _9"></span>(The <span class="_ _2"></span>summary <span class="_ _9"></span>and <span class="_ _2"></span>ANOVA <span class="_ _9"></span>table <span class="_ _2"></span>of <span class="_ _9"></span>this </div><div class="t m0 x8 ha y6b ff4 fs6 fc1 sc0 ls0 ws0">model is in figure 8 and 9) </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf4" class="pf w0 h0" data-page-no="4"><div class="pc pc4 w0 h0"><img class="bi x52 y6c w6 h11" alt="" src="bg4.png"/><div class="c x1 y1 w2 h2"><div class="t m0 x53 ha y6d ff4 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x10 ha y6e ff4 fs6 fc1 sc0 ls0 ws0">We can use Wald Test to test single <span class="ff6">b</span>.  Ho: <span class="ff6">b</span></div><div class="t m0 x54 he y6f ff4 fs7 fc1 sc0 ls0 ws0">k</div><div class="t m0 x55 ha y6e ff4 fs6 fc1 sc0 ls0 ws0"> = 0 v.s. H</div><div class="t m0 x56 he y6f ff4 fs7 fc1 sc0 ls0 ws0">1</div><div class="t m0 x57 ha y6e ff4 fs6 fc1 sc0 ls9 ws0">: <span class="ff6 ls0">b</span></div><div class="t m0 x58 he y6f ff4 fs7 fc1 sc0 ls0 ws0">k</div><div class="t m0 x59 h10 y6e ff4 fs6 fc1 sc0 ls0 ws0"> <span class="ff7">!</span> 0 (k = 0…5). Here the p-</div><div class="t m0 x8 ha y15 ff4 fs6 fc1 sc0 ls0 ws0">value of <span class="ff6">b</span></div><div class="t m0 x5a he y70 ff4 fs7 fc1 sc0 lsc ws0">1, </div><div class="t m0 x5b hf y15 ff6 fs6 fc1 sc0 ls0 ws0">b</div><div class="t m0 x32 he y70 ff4 fs7 fc1 sc0 lsc ws0">2, </div><div class="t m0 x5c hf y15 ff6 fs6 fc1 sc0 ls0 ws0">b</div><div class="t m0 x5d he y70 ff4 fs7 fc1 sc0 lsc ws0">3 </div><div class="t m0 x24 ha y15 ff4 fs6 fc1 sc0 ls0 ws0">and <span class="ff6">b</span></div><div class="t m0 x38 he y70 ff4 fs7 fc1 sc0 ls0 ws0">4</div><div class="t m0 x5e ha y15 ff4 fs6 fc1 sc0 ls0 ws0"> are less than <span class="ff6">a</span> = 0.05, we fail to reject the null hypothesis. The p-value </div><div class="t m0 x8 ha y71 ff4 fs6 fc1 sc0 ls0 ws0">of the second order variable is a little bit higher than <span class="ff6">a</span> = 0.05, but it is very close to 0.05. We </div><div class="t m0 x8 ha y72 ff4 fs6 fc1 sc0 ls0 ws0">can further use Deviance Goodness of fit test to test if the model is appropriate. </div><div class="t m0 x10 ha y73 ff4 fs6 fc1 sc0 ls9 ws0">We <span class="ls0">also compare this selected model with the saturated model.(ANOVA model of </span></div><div class="t m0 x8 ha y74 ff4 fs6 fc1 sc0 ls0 ws0">saturated model is in the figure 11) </div><div class="t m0 x8 ha y1a ff4 fs6 fc1 sc0 ls0 ws0">Ho: <span class="_ _9"></span>logit(Status)=0.1472-2.2760*TotalL+2.0814*HumerusL <span class="_ _9"></span>-1.1443*<span class="ls9">ln</span>(Wght) <span class="_ _4"></span>+ <span class="_ _9"></span>0.9354*KeelL </div><div class="t m0 x8 ha y75 ff4 fs6 fc1 sc0 ls0 ws0">+ 0.5426*FemurL</div><div class="t m0 x5f he y76 ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x60 ha y75 ff4 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x8 ha y77 ff4 fs6 fc1 sc0 ls0 ws0">H1: The model is not a good fit. </div><div class="t m0 x8 ha y78 ff4 fs6 fc1 sc0 ls0 ws0">G</div><div class="t m0 x35 he y79 ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x36 ha y78 ff4 fs6 fc1 sc0 ls0 ws0"> = -2[logL(R) – logL(F)] = 65.223 – 51.814 = 13.409 </div><div class="t m0 x8 hf y7a ff6 fs6 fc1 sc0 ls0 ws0">c</div><div class="t m0 x21 he y7b ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x22 ha y7a ff4 fs6 fc1 sc0 ls0 ws0"> (1-0.05, 81-67) = <span class="ff6">c</span></div><div class="t m0 x37 he y7b ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x38 ha y7a ff4 fs6 fc1 sc0 ls0 ws0"> (0.95, 14) = 23.7 </div><div class="t m0 x8 ha y7c ff4 fs6 fc1 sc0 ls0 ws0">Since <span class="_ _7"></span>G</div><div class="t m0 x39 he y7d ff4 fs7 fc1 sc0 ls0 ws0">2 </div><div class="t m0 x3a ha y7c ff4 fs6 fc1 sc0 ls0 ws0">is <span class="_ _7"></span>much smaller <span class="_ _7"></span>than <span class="ff6">c</span></div><div class="t m0 x61 he y7d ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x4 ha y7c ff4 fs6 fc1 sc0 ls0 ws0"> <span class="_ _7"></span>(0.95, 14) <span class="_ _7"></span>= 23.7, <span class="_ _7"></span>we fail <span class="_ _7"></span>to <span class="_ _7"></span>reject the <span class="_ _7"></span>null hypothesis. <span class="_ _7"></span>The <span class="_ _7"></span>model </div><div class="t m0 x8 ha y7e ff4 fs6 fc1 sc0 ls9 ws0">is:<span class="ls0"> logit(Status)=0.1472-2.2760*TotalL+2.0814*HumerusL -1.1443*</span>ln<span class="ls0">(Wght) + 0.9354*KeelL <span class="_ _2"></span>+ </span></div><div class="t m0 x8 ha y5 ff4 fs6 fc1 sc0 ls0 ws0">0.5426*FemurL</div><div class="t m0 x5d he y7f ff4 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x2d ha y5 ff4 fs6 fc1 sc0 ls0 ws0"> , is a good fit of the sparrow data. </div><div class="t m0 x8 ha y80 ff4 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x9 hc y81 ff3 fs6 fc1 sc0 ls0 ws0">3.<span class="ff5"> <span class="_ _3"> </span></span>Interaction Selection </div><div class="t m0 x10 ha y82 ff4 fs6 fc1 sc0 ls0 ws0">W<span class="ls9">e <span class="_ _7"></span>al<span class="ls0">so fit <span class="_ _7"></span>the model <span class="_ _7"></span>with all <span class="_ _7"></span>the first <span class="_ _7"></span>order and <span class="_ _7"></span>interaction <span class="_ _7"></span>term and <span class="_ _7"></span>use forward <span class="_ _7"></span>selection </span></span></div><div class="t m0 x8 ha y83 ff4 fs6 fc1 sc0 ls0 ws0">to <span class="_ _0"></span>choose <span class="_ _7"></span>the best <span class="_ _7"></span>model. The <span class="_ _7"></span>model chosen <span class="_ _7"></span>by forward <span class="_ _7"></span>selection procedure <span class="_ _7"></span>is exactly <span class="_ _7"></span>the same <span class="_ _7"></span>as </div><div class="t m0 x8 ha y84 ff4 fs6 fc1 sc0 ls0 ws0">the best <span class="_ _7"></span>model in <span class="_ _7"></span>the first-order model: <span class="_ _7"></span>logit(Status) = <span class="_ _7"></span>0.6335 - 2.0292*TotalL <span class="_ _7"></span>- 1.0690*<span class="ls9">ln</span>(Wght) </div><div class="t m0 x8 ha y85 ff4 fs6 fc1 sc0 ls0 ws0">+ <span class="_ _2"></span>1.6133 <span class="_ _9"></span>HumerusL <span class="_ _9"></span>+ <span class="_ _2"></span>0.9245*<span class="lsb">KeelL</span>.Therefore, <span class="_ _9"></span>we <span class="_ _9"></span>selected <span class="_ _2"></span>two <span class="_ _9"></span>model <span class="_ _9"></span>to <span class="_ _2"></span>fit <span class="_ _9"></span>the <span class="_ _9"></span>data, <span class="_ _2"></span>one <span class="_ _9"></span>is <span class="_ _9"></span>in </div><div class="t m0 x8 ha y86 ff4 fs6 fc1 sc0 ls0 ws0">the first order and one is in the second: </div><div class="t m0 x8 ha y87 ff4 fs6 fc1 sc0 ls0 ws0">First order model: </div><div class="t m0 x9 hf y88 ff8 fs6 fc1 sc0 ls0 ws0">logit(Status) =0.6335-2.0292*TotalL-1.0690*<span class="ls9">ln</span>(Wght)+1.6133HumerusL+0.9245*KeelL </div><div class="t m0 x8 ha y89 ff4 fs6 fc1 sc0 ls0 ws0">Second order model: </div><div class="t m0 x9 hf y8a ff8 fs6 fc1 sc0 ls0 ws0">logit(Status)=0.1472-2.2760*TotalL+2.0814*HumerusL-1.1443*<span class="ls9">ln</span>(Wght)+0.9354*KeelL+ </div><div class="t m0 x9 hf y8b ff8 fs6 fc1 sc0 ls0 ws0">0.5426*FemurL</div><div class="t m0 x62 h12 y8c ff8 fs7 fc1 sc0 ls0 ws0">2</div><div class="t m0 x63 hf y8b ff8 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x8 ha y8d ff4 fs6 fc1 sc0 ls0 ws0">We <span class="_ _0"></span>will <span class="_ _7"></span>further analyze <span class="_ _7"></span>these two <span class="_ _7"></span>models and <span class="_ _7"></span>selected a <span class="_ _7"></span>final model <span class="_ _7"></span>in the <span class="_ _7"></span>Model Diagnostic <span class="_ _7"></span>part. </div><div class="t m0 xb h6 y8e ff3 fs4 fc1 sc0 ls0 ws0"> </div><div class="t m0 x64 h6 y8f ff3 fs4 fc1 sc0 lse ws0">Model <span class="ls8">Diagnostic<span class="ls0"> </span></span></div><div class="t m0 x10 ha y90 ff4 fs6 fc1 sc0 ls0 ws0">We fit the two models individually and plot the Pearson residual, Studentized Pearson </div><div class="t m0 x8 ha y91 ff4 fs6 fc1 sc0 ls0 ws0">residuals and Deviance residuals against fitted probability, as well as half normal plot </div><div class="t m0 x8 ha y92 ff4 fs6 fc1 sc0 ls0 ws0">(Figure12&amp;Figure14). We also look at the scatter plot of the residuals, and noticed possible </div><div class="t m0 x8 ha y93 ff4 fs6 fc1 sc0 ls0 ws0">outliers (Figure13&amp;Figure15).  We removed the corresponding outliers and refit the models </div><div class="t m0 x8 ha y94 ff4 fs6 fc1 sc0 ls0 ws0">again. We compare the model by looking at 95% confidence interval for all estimate coefficients, </div><div class="t m0 x8 ha y95 ff4 fs6 fc1 sc0 ls0 ws0">5 fold cross validation accuracy, proportion of reduction error which we define as 1- </div><div class="t m0 x65 h13 y96 ff7 fs8 fc1 sc0 ls0 ws0">$%</div><div class="t m0 x66 h14 y97 ff7 fs9 fc1 sc0 ls0 ws0">&amp;</div><div class="t m0 x67 h13 y96 ff7 fs8 fc1 sc0 ls0 ws0">&apos;&quot;(</div><div class="t m0 x68 h14 y97 ff7 fs9 fc1 sc0 ls0 ws0">&amp;</div><div class="t m0 x69 h13 y96 ff7 fs8 fc1 sc0 ls0 ws0">)*+</div><div class="t m0 x6a h13 y98 ff7 fs8 fc1 sc0 ls0 ws0">$%</div><div class="t m0 x6b h14 y99 ff7 fs9 fc1 sc0 ls0 ws0">&amp;</div><div class="t m0 x48 h13 y98 ff7 fs8 fc1 sc0 ls0 ws0">&apos;&quot;%<span class="_ _2"></span>)*+</div><div class="t m0 x6c ha y95 ff4 fs6 fc1 sc0 ls0 ws0">, </div><div class="t m0 x8 ha y9a ff4 fs6 fc1 sc0 ls0 ws0">area under the curve, and its 95% confidence interval for AUC. Below is a summary of the two </div><div class="t m0 x8 ha y9b ff4 fs6 fc1 sc0 ls0 ws0">models: </div><div class="t m0 x8 ha y9c ff4 fs6 fc1 sc0 ls0 ws0"> </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf5" class="pf w0 h0" data-page-no="5"><div class="pc pc5 w0 h0"><img class="bi x6d y9d w7 h15" alt="" src="bg5.png"/><div class="c x1 y1 w2 h2"><div class="t m0 x8 ha y9e ff4 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x8 ha y9f ff4 fs6 fc1 sc0 ls0 ws0">Model 2 wins over model 1 in all aspect, so we chose model 2 to be our final logistic model:   </div><div class="t m0 x8 ha ya0 ff4 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x14 hc ya1 ff3 fs6 fc1 sc0 ls0 ws0">logit(Status) = -0.02171 - 2.70422*Total _Length - 1.41988* ln(Wight) +  </div><div class="t m0 x6e hc ya2 ff3 fs6 fc1 sc0 ls0 ws0">2.59218*Humerus_Length + 1.27886*<span class="ls9">Keel</span>_Length + 0.73053*(Femur_Length)^2 </div><div class="t m0 x8 h6 ya3 ff3 fs4 fc1 sc0 ls0 ws0"> </div><div class="t m0 xb h6 ya4 ff3 fs4 fc1 sc0 ls0 ws0"> </div><div class="t m0 x6f h6 ya5 ff3 fs4 fc1 sc0 ls8 ws0">Conclus<span class="lsf">ion and Discussion<span class="ls0"> </span></span></div><div class="t m0 x8 ha ya6 ff4 fs6 fc1 sc0 ls0 ws0">Since the all the coefficient intervals do not contain zero at 95% confidence level, the model </div><div class="t m0 x8 ha ya7 ff4 fs6 fc1 sc0 ls0 ws0">does suggest total length, weight, Humerus length, keel length and square of fumur length have </div><div class="t m0 x8 ha ya8 ff4 fs6 fc1 sc0 ls0 ws0">effect on the status of house sparrow. Further interpret for each coefficient, we have:   </div><div class="t m0 x9 ha ya9 ff9 fs6 fc1 sc0 ls0 ws0">•<span class="ffa"> <span class="_ _a"> </span><span class="ff4">When total length increase by 1 unit, the odd for house sparrow to survived is decreased </span></span></div><div class="t m0 x10 h10 yaa ff4 fs6 fc1 sc0 ls0 ws0">by 93% (<span class="ff7">,</span></div><div class="t m0 x2e h13 yab ff7 fs8 fc1 sc0 ls0 ws0">+-.</div><div class="t m0 x2f ha yaa ff4 fs6 fc1 sc0 ls0 ws0">) </div><div class="t m0 x9 ha yac ff9 fs6 fc1 sc0 ls0 ws0">•<span class="ffa"> <span class="_ _a"> </span><span class="ff4">When weight increase by 1 unit, the odd for house sparrow to survive is decreased by </span></span></div><div class="t m0 x10 h10 yad ff4 fs6 fc1 sc0 ls0 ws0">86% <span class="ff7">$,</span></div><div class="t m0 x70 h13 yae ff7 fs8 fc1 sc0 ls0 ws0">&apos;/-<span class="ls10">0+</span></div><div class="t m0 x62 ha yad ff4 fs6 fc1 sc0 ls0 ws0">). </div><div class="t m0 x9 ha yaf ff9 fs6 fc1 sc0 ls0 ws0">•<span class="ffa"> <span class="_ _a"> </span><span class="ff4">When humerus length increase by 1 unit, the odd for house sparrow to survived is </span></span></div><div class="t m0 x10 h10 yb0 ff4 fs6 fc1 sc0 ls0 ws0">increase by 12.36 times. (<span class="ff7">,</span></div><div class="t m0 x1a h13 yb1 ff7 fs8 fc1 sc0 ls0 ws0">+-<span class="ls10">12</span></div><div class="t m0 x71 ha yb0 ff4 fs6 fc1 sc0 ls0 ws0">) </div><div class="t m0 x9 ha yb2 ff9 fs6 fc1 sc0 ls0 ws0">•<span class="ffa"> <span class="_ _a"> </span><span class="ff4">When Keel length increase by 1 unit, the odd for house sparrow to survived is increased </span></span></div><div class="t m0 x10 h10 yb3 ff4 fs6 fc1 sc0 ls0 ws0">by 2.6 times (<span class="ff7">,</span></div><div class="t m0 x72 h13 yb4 ff7 fs8 fc1 sc0 ls0 ws0">/-<span class="ls10">+3</span></div><div class="t m0 x73 ha yb3 ff4 fs6 fc1 sc0 ls0 ws0">). </div><div class="t m0 x9 ha yb5 ff9 fs6 fc1 sc0 ls0 ws0">•<span class="ffa"> <span class="_ _a"> </span><span class="ff4">When square of Femur lengths increase by 1 unit, the odd for house sparrow to survived </span></span></div><div class="t m0 x10 h10 yb6 ff4 fs6 fc1 sc0 ls0 ws0">is increased by 1.1 times (<span class="ff7">,</span></div><div class="t m0 x74 h13 yb7 ff7 fs8 fc1 sc0 ls0 ws0">4-<span class="ls10">.5</span></div><div class="t m0 x64 ha yb6 ff4 fs6 fc1 sc0 ls0 ws0">). </div><div class="t m0 x8 ha yb8 ff4 fs6 fc1 sc0 ls0 ws0">A side note to the interpretation above, since we took natural log of weight and also scaled <span class="ls9">all </span></div><div class="t m0 x8 ha yb9 ff4 fs6 fc1 sc0 ls0 ws0">variables, instead of using variable unit, we use unit-less unit in the interpretation. </div><div class="t m0 x8 ha yba ff4 fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x10 ha ybb ff4 fs6 fc1 sc0 ls9 ws0">We <span class="ls0">notice that some scientists also find out the width of skull may influence sparrows’ </span></div><div class="t m0 x8 ha ybc ff4 fs6 fc1 sc0 ls0 ws0">survival status, but our final model does no<span class="ls9">t </span>show this aspect. To include this variable, we may </div><div class="t m0 x8 ha ybd ff4 fs6 fc1 sc0 ls0 ws0">need to do further research to improve the final model. Some people also use other method to fit </div><div class="t m0 x8 ha ybe ff4 fs6 fc1 sc0 ls0 ws0">the data, such as Structural equation modelling, so the logistic regression is not the only choice. </div></div><div class="c x6d ybf w8 h16"><div class="t m0 x75 ha yc0 ff4 fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c xa ybf w9 h16"><div class="t m0 x0 ha yc0 ff4 fs6 fc1 sc0 ls0 ws0">Model 1 </div></div><div class="c x42 ybf wa h16"><div class="t m0 x76 ha yc0 ff4 fs6 fc1 sc0 ls0 ws0">Model 2 </div></div><div class="c x6d yc1 w8 h17"><div class="t m0 x77 ha yc2 ff4 fs6 fc1 sc0 ls0 ws0">Variables </div></div><div class="c xa yc1 w9 h17"><div class="t m0 x78 ha yc2 ff4 fs6 fc1 sc0 ls0 ws0">Total Length, Wight, Humerus </div><div class="t m0 x79 ha yc3 ff4 fs6 fc1 sc0 ls0 ws0">Length, Keel Length </div></div><div class="c x42 yc1 wa h17"><div class="t m0 x7a ha yc2 ff4 fs6 fc1 sc0 ls0 ws0">Total Length, Wight, Humerus </div><div class="t m0 x7b ha yc3 ff4 fs6 fc1 sc0 ls0 ws0">Length, Keel Length, Femur </div><div class="t m0 x7c ha yc4 ff4 fs6 fc1 sc0 ls0 ws0">Length Square </div></div><div class="c x6d yc5 w8 h18"><div class="t m0 x7d ha yc6 ff4 fs6 fc1 sc0 ls0 ws0">95 CI Interval </div></div><div class="c xa yc5 w9 h18"><div class="t m0 x7e ha yc7 ff4 fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x42 yc5 wa h18"><div class="t m0 x72 ha yc8 ff4 fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x6d yc9 w8 h19"><div class="t m0 x7f ha yca ff4 fs6 fc1 sc0 ls0 ws0">Outliers  </div></div><div class="c xa yc9 w9 h19"><div class="t m0 x80 ha yca ff4 fs6 fc1 sc0 ls0 ws0">2 </div></div><div class="c x42 yc9 wa h19"><div class="t m0 x2c ha yca ff4 fs6 fc1 sc0 ls0 ws0">1 </div></div><div class="c x6d ycb w8 h1a"><div class="t m0 x81 ha ycc ff4 fs6 fc1 sc0 ls0 ws0">5-Fold CV Accuracy </div></div><div class="c xa ycb w9 h1a"><div class="t m0 x22 ha ycc ff4 fs6 fc1 sc0 ls0 ws0">0.7882353 </div></div><div class="c x42 ycb wa h1a"><div class="t m0 x22 ha ycc ff4 fs6 fc1 sc0 ls0 ws0">0.824183 </div></div><div class="c x6d ycd w8 h1b"><div class="t m0 x82 ha yc3 ff4 fs6 fc1 sc0 ls0 ws0">Proportion of  </div><div class="t m0 x83 ha yce ff4 fs6 fc1 sc0 ls0 ws0">Reduction in Error </div></div><div class="c xa ycd w9 h1b"><div class="t m0 x22 ha yc3 ff4 fs6 fc1 sc0 ls0 ws0">0.5335469 </div></div><div class="c x42 ycd wa h1b"><div class="t m0 x35 ha yc3 ff4 fs6 fc1 sc0 ls0 ws0">0.5669628 </div></div><div class="c x6d ycf w8 h1c"><div class="t m0 x84 ha yd0 ff4 fs6 fc1 sc0 lsb ws0">AUC<span class="ls0"> </span></div></div><div class="c xa ycf w9 h1c"><div class="t m0 x6d ha yd0 ff4 fs6 fc1 sc0 ls0 ws0">0.9251 </div></div><div class="c x42 ycf wa h1c"><div class="t m0 x85 ha yd0 ff4 fs6 fc1 sc0 ls0 ws0">0.93 </div></div><div class="c x6d yd1 w8 h1a"><div class="t m0 x7d ha ycc ff4 fs6 fc1 sc0 ls0 ws0">95% CI AUC </div></div><div class="c xa yd1 w9 h1a"><div class="t m0 x8 ha ycc ff4 fs6 fc1 sc0 ls0 ws0">[0.8733,0.977]  </div></div><div class="c x42 yd1 wa h1a"><div class="t m0 x8 ha ycc ff4 fs6 fc1 sc0 ls0 ws0">[0.878, 0.982] </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf6" class="pf w0 h0" data-page-no="6"><div class="pc pc6 w0 h0"><img class="bi x8 y1 wb h1d" alt="" src="bg6.png"/><div class="c x1 y1 w2 h2"><div class="t m0 x7f h1e yd2 ffb fs6 fc1 sc0 ls0 ws0">Appendix (all the plot) </div><div class="t m0 x7f h1e yd3 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 yd4 wc h1f"><div class="t m0 x4d h1e yd5 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 yd6 wc h20"><div class="t m0 x51 h1e yc4 ffb fs6 fc1 sc0 ls0 ws0">Figure 1 </div></div><div class="c x8 yd7 wc h21"><div class="t m0 x86 h1e yd5 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 yd8 wc h20"><div class="t m0 x51 h1e yc4 ffb fs6 fc1 sc0 ls0 ws0">Figure 2 </div></div><div class="c x1 y1 w2 h2"><div class="t m0 x7f h22 yd9 ffb fsa fc1 sc0 ls0 ws0"> </div></div><div class="c x8 yda wc h23"><div class="t m0 x87 h1e yc8 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 y1 wc h24"><div class="t m0 x51 h1e ydb ffb fs6 fc1 sc0 ls0 ws0">Figure 3 </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf7" class="pf w0 h0" data-page-no="7"><div class="pc pc7 w0 h0"><img class="bi x8 ydc wb h25" alt="" src="bg7.png"/><div class="c x8 ydd wc h26"><div class="t m0 x45 h1e yc8 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 yde wc h27"><div class="t m0 x51 h1e yce ffb fs6 fc1 sc0 ls0 ws0">Figure 4 </div></div><div class="c x8 ydf wc h28"><div class="t m0 x65 h1e yd5 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 ye0 wc h29"><div class="t m0 x51 h1e ye1 ffb fs6 fc1 sc0 ls0 ws0">Figure 5 </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf8" class="pf w0 h0" data-page-no="8"><div class="pc pc8 w0 h0"><img class="bi x8 ye2 wd h2a" alt="" src="bg8.png"/><div class="c x8 ye3 wc h2b"><div class="t m0 x6c h1e yd5 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 ye4 wc h27"><div class="t m0 x38 h1e yce ffb fs6 fc1 sc0 ls0 ws0">Figure 6 (Best model for first-order) </div></div><div class="c x8 ye5 wc h2c"><div class="t m0 x1f h1e yd5 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 ye6 wc h20"><div class="t m0 x2c h1e yc4 ffb fs6 fc1 sc0 ls0 ws0">Figure 7 (A<span class="lsb">NOVA</span> table for best first-order model) (Reduced model) </div></div><div class="c x8 ye7 wc h2d"><div class="t m0 x88 h1e ye8 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 ye9 wc h20"><div class="t m0 x6e h1e yc4 ffb fs6 fc1 sc0 ls0 ws0">Figure 8 (A<span class="lsb">NOVA</span> table for full model in first-order) (Saturated model) </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf9" class="pf w0 h0" data-page-no="9"><div class="pc pc9 w0 h0"><img class="bi x8 yea wb h2e" alt="" src="bg9.png"/><div class="c x8 yeb wc h2f"><div class="t m0 x20 h1e yd5 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 yec wc h20"><div class="t m0 x30 h1e yc4 ffb fs6 fc1 sc0 ls0 ws0">Figure 9 (Best model for second-order) </div></div><div class="c x8 yed wc h30"><div class="t m0 x46 h1e yd5 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 yee wc h20"><div class="t m0 x85 h1e yc4 ffb fs6 fc1 sc0 ls0 ws0">Figure 10 (A<span class="lsb">NOVA</span> table for best second-order model)(Reduced model) </div></div><div class="c x8 yef wc h31"><div class="t m0 x89 h1e yc8 ffb fs6 fc1 sc0 ls0 ws0"> </div></div><div class="c x8 yf0 wc h27"><div class="t m0 x0 h1e yce ffb fs6 fc1 sc0 ls0 ws0">Figure 11 (A<span class="lsb">NOVA</span> table for full model in second-order) (Saturated model) </div></div><div class="c x1 y1 w2 h2"><div class="t m0 x7f h1e yf1 ffb fs6 fc1 sc0 ls0 ws0"> </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfa" class="pf w0 h0" data-page-no="a"><div class="pc pca w0 h0"><img class="bi x8 yf2 we h32" alt="" src="bga.png"/><div class="c x8 yf3 wf h1c"><div class="t m0 x50 h33 yd ffc fs6 fc1 sc0 ls0 ws0">Model&amp;1&amp;Residul&amp;Plot&amp;&amp;</div></div><div class="c x8 yf4 wf h34"><div class="t m0 x8a h33 yc8 ffc fs6 fc1 sc0 ls0 ws0">&amp;</div></div><div class="c x8 yf5 wf h1c"><div class="t m0 x11 h33 yd ffc fs6 fc1 sc0 ls11 ws0">Figure&amp;12<span class="ls0">&amp;</span></div></div><div class="c x8 yf6 wf h35"><div class="t m0 x8b h33 yd5 ffc fs6 fc1 sc0 ls0 ws0">&amp;</div></div><div class="c x8 yf7 wf h1c"><div class="t m0 x11 h33 yd ffc fs6 fc1 sc0 ls0 ws0">F<span class="ls11">igure&amp;<span class="ls9">13</span></span>&amp;</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfb" class="pf w0 h0" data-page-no="b"><div class="pc pcb w0 h0"><img class="bi x8 yf8 we h36" alt="" src="bgb.png"/><div class="c x8 yf9 wf h37"><div class="t m0 x8c h33 yd5 ffc fs6 fc1 sc0 ls0 ws0">&amp;</div></div><div class="c x8 yfa wf h1c"><div class="t m0 x11 h33 yd ffc fs6 fc1 sc0 ls11 ws0">Figure&amp;14<span class="ls0">&amp;</span></div></div><div class="c x8 yfb wf h38"><div class="t m0 x81 h33 yfc ffc fs6 fc1 sc0 ls0 ws0">&amp;</div><div class="t m0 x8d h33 yc8 ffc fs6 fc1 sc0 ls0 ws0">&amp;</div></div><div class="c x8 yfd wf h1c"><div class="t m0 x11 h33 yd ffc fs6 fc1 sc0 ls11 ws0">Figure&amp;15<span class="ls0">&amp;</span></div></div><div class="c x1 y1 w2 h2"><div class="t m0 x7f h1e yfe ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e yff ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y100 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y101 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y102 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y103 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y104 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y105 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y106 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y107 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y108 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y109 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y10a ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y10b ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y10c ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y10d ffb fs6 fc1 sc0 ls0 ws0"> </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfc" class="pf w0 h0" data-page-no="c"><div class="pc pcc w0 h0"><div class="c x1 y1 w2 h2"><div class="t m0 x7f h1e yd2 ffb fs6 fc1 sc0 ls0 ws0">Appendix (all the R-code): </div><div class="t m0 x7f h1e yd3 ffb fs6 fc1 sc0 ls0 ws0">setwd(&quot;~/Desktop&quot;) </div><div class="t m0 x7f h1e y10e ffb fs6 fc1 sc0 ls0 ws0">library(openxlsx) </div><div class="t m0 x7f h1e y10f ffb fs6 fc1 sc0 ls0 ws0">library(corrplot) </div><div class="t m0 x7f h1e y110 ffb fs6 fc1 sc0 ls0 ws0">Data = read.xlsx(&quot;survival_sparrow.xlsx&quot;) </div><div class="t m0 x7f h1e y111 ffb fs6 fc1 sc0 ls0 ws0">names(Data) </div><div class="t m0 x7f h1e y112 ffb fs6 fc1 sc0 ls0 ws0">names(Data)=c(&apos;Status&apos;,&apos;Age&apos;,&apos;TotalL&apos;,&apos;AlarExtL&apos;, </div><div class="t m0 x7f h1e y113 ffb fs6 fc1 sc0 ls0 ws0">            &apos;Wght&apos;,&apos;BeakHeadL&apos;,&apos;HumerusL&apos;, </div><div class="t m0 x7f h1e y114 ffb fs6 fc1 sc0 ls0 ws0">            &apos;FemurL&apos;,&apos;TribioTarsusL&apos;,&apos;SkullWd&apos;,&apos;KeelL&apos;) </div><div class="t m0 x7f h1e y115 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y116 ffb fs6 fc1 sc0 ls0 ws0"># Data processing </div><div class="t m0 x7f h1e y117 ffb fs6 fc1 sc0 ls0 ws0">#multicollinearity </div><div class="t m0 x7f h1e y118 ffb fs6 fc1 sc0 ls0 ws0">dim(Data) </div><div class="t m0 x7f h1e y119 ffb fs6 fc1 sc0 lsb ws0">Data[<span class="ls0">Data$Status==&apos;Perished&apos;,]$Status= 0 </span></div><div class="t m0 x7f h1e y11a ffb fs6 fc1 sc0 ls0 ws0">Data[Data$Status==&apos;Survived&apos;,]$Status = 1 </div><div class="t m0 x7f h1e y11b ffb fs6 fc1 sc0 ls0 ws0">Data$Status = as.numeric(Data$Status) </div><div class="t m0 x7f h1e y11c ffb fs6 fc1 sc0 ls0 ws0">Data$Age  = as.numeric(Data$Age ) </div><div class="t m0 x7f h1e y11d ffb fs6 fc1 sc0 ls0 ws0">sapply(Data,class) </div><div class="t m0 x7f h1e y11e ffb fs6 fc1 sc0 ls0 ws0">X_cts = as.data.frame(Data[,3:11]) </div><div class="t m0 x7f h1e y11f ffb fs6 fc1 sc0 ls0 ws0">pairs(X_cts, main=&apos;Correlation between all x variabl<span class="ls9">es&apos;)</span> </div><div class="t m0 x7f h1e y120 ffb fs6 fc1 sc0 ls0 ws0">corrplot.mixed(cor(X_cts),lower = &quot;number&quot;, upper=&quot;ellipse&quot;)  </div><div class="t m0 x7f h1e y121 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y122 ffb fs6 fc1 sc0 ls0 ws0">par(mfrow=c(3, 3)) </div><div class="t m0 x7f h1e y123 ffb fs6 fc1 sc0 ls0 ws0">for (i in 1:9){ </div><div class="t m0 x7f h1e y124 ffb fs6 fc1 sc0 ls0 ws0">  hist(X_cts[,i], main = names(Data)[i+2]) </div><div class="t m0 x7f h1e y125 ffb fs6 fc1 sc0 ls0 ws0">} </div><div class="t m0 x7f h1e y126 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y127 ffb fs6 fc1 sc0 ls0 ws0">#check if we need to do transformation on X continuous variable  </div><div class="t m0 x7f h1e y128 ffb fs6 fc1 sc0 ls0 ws0">Data$Wght = log(X_cts$Wght) </div><div class="t m0 x7f h1e y129 ffb fs6 fc1 sc0 ls0 ws0">Data$BeakHeadL= log(X_cts$BeakHeadL) </div><div class="t m0 x7f h1e y12a ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y12b ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y12c ffb fs6 fc1 sc0 ls0 ws0">#standarized quantitative variable variables </div><div class="t m0 x7f h1e y12d ffb fs6 fc1 sc0 ls0 ws0">for (i in 3:11){ </div><div class="t m0 x7f h1e y12e ffb fs6 fc1 sc0 ls0 ws0">  Data[,i] = (Data[,i]-mean(Data[,i]))/sd(Data[,i]) </div><div class="t m0 x7f h1e y12f ffb fs6 fc1 sc0 ls0 ws0">} </div><div class="t m0 x7f h1e y130 ffb fs6 fc1 sc0 ls0 ws0">X_cts = as.data.frame(Data[,3:11]) </div><div class="t m0 x7f h1e y131 ffb fs6 fc1 sc0 ls0 ws0">par(mfrow=c(3, 3)) </div><div class="t m0 x7f h1e y132 ffb fs6 fc1 sc0 ls0 ws0">for (i in 1:9){ </div><div class="t m0 x7f h1e y133 ffb fs6 fc1 sc0 ls0 ws0">  hist(X_cts[,i], main = names(Data)[i+2]) </div><div class="t m0 x7f h1e y134 ffb fs6 fc1 sc0 ls0 ws0">} </div><div class="t m0 x7f h1e y135 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y136 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y137 ffb fs6 fc1 sc0 ls0 ws0">par(mfrow=c(3, 3)) </div><div class="t m0 x7f h1e y138 ffb fs6 fc1 sc0 ls0 ws0">for (i in 1:9){ </div><div class="t m0 x7f h1e y139 ffb fs6 fc1 sc0 ls0 ws0">  plot(X_cts[,i],Data$Status, main = names(Data)[i+2] ) </div><div class="t m0 x7f h1e y13a ffb fs6 fc1 sc0 ls0 ws0">  lines(lowess(data.frame(X_cts[,i],Data$Status)), col = 2) </div><div class="t m0 x7f h1e y13b ffb fs6 fc1 sc0 ls0 ws0">} </div><div class="t m0 x7f h1e y13c ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y13d ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y13e ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y13f ffb fs6 fc1 sc0 ls0 ws0">par(mfrow=c(1, 1)) </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfd" class="pf w0 h0" data-page-no="d"><div class="pc pcd w0 h0"><div class="c x1 y1 w2 h2"><div class="t m0 x7f h1e yd2 ffb fs6 fc1 sc0 ls0 ws0"># Fit with all fisrt-order  </div><div class="t m0 x7f h1e yd3 ffb fs6 fc1 sc0 ls0 ws0">logit.model =  glm(formula = Status ~., family = binomial(logit), data = Data) </div><div class="t m0 x7f h1e y10e ffb fs6 fc1 sc0 ls0 ws0">names(summary(logit.model)) </div><div class="t m0 x7f h1e y10f ffb fs6 fc1 sc0 ls0 ws0">summary(logit.model) </div><div class="t m0 x7f h1e y110 ffb fs6 fc1 sc0 ls0 ws0">fitted(logit.model) </div><div class="t m0 x7f h1e y111 ffb fs6 fc1 sc0 ls0 ws0">alpha = 0.05 </div><div class="t m0 x7f h1e y112 ffb fs6 fc1 sc0 ls0 ws0">confint(logit.model,level = (1-alpha)) </div><div class="t m0 x7f h1e y113 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y114 ffb fs6 fc1 sc0 ls0 ws0">#model slection stepwise/selection </div><div class="t m0 x7f h1e y115 ffb fs6 fc1 sc0 ls0 ws0">glm.control(epsilon = 1e-8, maxit = 100, trace = FALSE) </div><div class="t m0 x7f h1e y116 ffb fs6 fc1 sc0 ls0 ws0">full.model = glm(Status ~. , data =Data,family = binomial(link=logit),maxit = 100) </div><div class="t m0 x7f h1e y117 ffb fs6 fc1 sc0 ls0 ws0">#View(data.frame(fitted(full.model ),Data$Status)) </div><div class="t m0 x7f h1e y118 ffb fs6 fc1 sc0 ls0 ws0">empty.model = glm(Status~ 1 ,data = Data,family = binomial(link=logit)) </div><div class="t m0 x7f h1e y119 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y11a ffb fs6 fc1 sc0 ls0 ws0">#Forward selection and backward selection with AIC </div><div class="t m0 x7f h1e y11b ffb fs6 fc1 sc0 ls0 ws0">best.forward.AIC = step(empty.model,scope = list(lower = empty.model, upper = full.model),direction = </div><div class="t m0 x7f h1e y11c ffb fs6 fc1 sc0 ls0 ws0">&quot;forward&quot;, criterion = &quot;AIC&quot;, trace = FALSE) </div><div class="t m0 x7f h1e y11d ffb fs6 fc1 sc0 ls0 ws0">best.backward.AIC = step(full.model,scope = list(lower = empty.model, upper = full.model),direction = </div><div class="t m0 x7f h1e y11e ffb fs6 fc1 sc0 ls0 ws0">&quot;backward&quot;,  criterion = &quot;AIC&quot;, trace = FALSE) </div><div class="t m0 x7f h1e y11f ffb fs6 fc1 sc0 ls0 ws0">best.forward.AIC$formula # TotalL + Wght + HumerusL + KeelL </div><div class="t m0 x7f h1e y120 ffb fs6 fc1 sc0 ls0 ws0">best.backward.AIC$formula # TotalL + Wght + HumerusL + KeelL </div><div class="t m0 x7f h1e y121 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y122 ffb fs6 fc1 sc0 ls0 ws0">#Forward selection and backward selection with BIC </div><div class="t m0 x7f h1e y123 ffb fs6 fc1 sc0 ls0 ws0">best.forward.BIC = step(empty.model,scope = list(lower = empty.model, upper = full.model),direction = </div><div class="t m0 x7f h1e y124 ffb fs6 fc1 sc0 ls0 ws0">&quot;forward&quot;, criterion = &quot;AIC&quot;, k =log(87) , trace = FALSE) </div><div class="t m0 x7f h1e y125 ffb fs6 fc1 sc0 ls0 ws0">best.backward.BIC = step(full.model,scope = list(lower = empty.model, upper = full.model),direction = </div><div class="t m0 x7f h1e y126 ffb fs6 fc1 sc0 ls0 ws0">&quot;backward&quot;,  criterion = &quot;AIC&quot;,k =log(87) , trace = FALSE) </div><div class="t m0 x7f h1e y127 ffb fs6 fc1 sc0 ls0 ws0">best.forward.BIC$formula #TotalL + Wght + HumerusL + KeelL </div><div class="t m0 x7f h1e y128 ffb fs6 fc1 sc0 ls0 ws0">best.backward.BIC$formula #TotalL + Wght + HumerusL + KeelL </div><div class="t m0 x7f h1e y129 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y12a ffb fs6 fc1 sc0 ls0 ws0">#summary(best.backward.AIC) </div><div class="t m0 x7f h1e y12b ffb fs6 fc1 sc0 ls0 ws0">best.backward.AIC$formula </div><div class="t m0 x7f h1e y12c ffb fs6 fc1 sc0 ls0 ws0">summary(full.model) </div><div class="t m0 x7f h1e y12d ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y12e ffb fs6 fc1 sc0 ls0 ws0"># Fit the model with second order </div><div class="t m0 x7f h1e y12f ffb fs6 fc1 sc0 ls0 ws0"># remove the mean </div><div class="t m0 x7f h1e y130 ffb fs6 fc1 sc0 ls0 ws0">for (i in 3:11){ </div><div class="t m0 x7f h1e y131 ffb fs6 fc1 sc0 ls0 ws0">  Data[,i] = Data[,i]-mean(Data[,i])  </div><div class="t m0 x7f h1e y132 ffb fs6 fc1 sc0 ls0 ws0">} </div><div class="t m0 x7f h1e y133 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y134 ffb fs6 fc1 sc0 ls0 ws0">full.model = glm(Status ~. + I(TotalL^2)+I(AlarExtL^2)+ I(Wght^2)+ I(BeakHeadL^2) </div><div class="t m0 x7f h1e y135 ffb fs6 fc1 sc0 ls0 ws0">              +I(HumerusL^2)+I(FemurL^2)+I(TribioTarsusL^2)+I(SkullWd^2)+I(KeelL^2) , </div><div class="t m0 x7f h1e y136 ffb fs6 fc1 sc0 ls0 ws0">                 data =Data,family = binomial(link=logit),maxit = 100) </div><div class="t m0 x7f h1e y137 ffb fs6 fc1 sc0 ls0 ws0">summary(full.model) </div><div class="t m0 x7f h1e y138 ffb fs6 fc1 sc0 ls0 ws0">empty.model = glm(Status~ 1 ,data = Data,family = binomial(link=logit)) </div><div class="t m0 x7f h1e y139 ffb fs6 fc1 sc0 ls0 ws0">best.forward.AIC = step(empty.model,scope = list(lower = empty.model, upper = full.model),direction = </div><div class="t m0 x7f h1e y13a ffb fs6 fc1 sc0 ls0 ws0">&quot;forward&quot;, criterion = &quot;AIC&quot;, trace = FALSE) </div><div class="t m0 x7f h1e y13b ffb fs6 fc1 sc0 ls0 ws0">best.forward.BIC = step(empty.model,scope = list(lower = empty.model, upper = full.model),direction = </div><div class="t m0 x7f h1e y13c ffb fs6 fc1 sc0 ls0 ws0">&quot;forward&quot;, criterion = &quot;AIC&quot;,k =log(87) ,trace = FALSE) </div><div class="t m0 x7f h1e y13d ffb fs6 fc1 sc0 ls0 ws0">best.forward.AIC$formula  </div><div class="t m0 x7f h1e y13e ffb fs6 fc1 sc0 ls0 ws0">best.forward.AIC$formula  </div><div class="t m0 x7f h1e y13f ffb fs6 fc1 sc0 ls0 ws0"> </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfe" class="pf w0 h0" data-page-no="e"><div class="pc pce w0 h0"><div class="c x1 y1 w2 h2"><div class="t m0 x7f h1e yd2 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e yd3 ffb fs6 fc1 sc0 ls0 ws0">fullnew = best.forward.AIC </div><div class="t m0 x7f h1e y10e ffb fs6 fc1 sc0 ls0 ws0">best.backward.AIC = step(fullnew,scope = list(lower = empty.model, upper = fullnew),direction = </div><div class="t m0 x7f h1e y10f ffb fs6 fc1 sc0 ls0 ws0">&quot;backward&quot;,  criterion = &quot;AIC&quot;, trace = FALSE) </div><div class="t m0 x7f h1e y110 ffb fs6 fc1 sc0 ls0 ws0">best.backward.BIC = step(fullnew,scope = list(lower = empty.model, upper = fullnew),direction = </div><div class="t m0 x7f h1e y111 ffb fs6 fc1 sc0 ls0 ws0">&quot;backward&quot;,  criterion = &quot;AIC&quot;,k =log(87) , trace = FALSE) </div><div class="t m0 x7f h1e y112 ffb fs6 fc1 sc0 ls0 ws0">best.backward.AIC$formula </div><div class="t m0 x7f h1e y113 ffb fs6 fc1 sc0 ls0 ws0">best.backward.BIC$formula </div><div class="t m0 x7f h1e y114 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y115 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y116 ffb fs6 fc1 sc0 ls0 ws0"># fit the model with interaction term </div><div class="t m0 x7f h1e y117 ffb fs6 fc1 sc0 ls0 ws0">glm.control(epsilon = 1e-8, maxit = 100, trace = FALSE) </div><div class="t m0 x7f h1e y118 ffb fs6 fc1 sc0 ls0 ws0">full.model = glm(Status ~. + .*. ,data =Data,family = binomial(link=logit),maxit = 100) </div><div class="t m0 x7f h1e y119 ffb fs6 fc1 sc0 ls0 ws0">#View(data.frame(fitted(full.model ),Data$Status)) </div><div class="t m0 x7f h1e y11a ffb fs6 fc1 sc0 ls0 ws0">empty.model = glm(Status~ 1 ,data = Data,family = binomial(link=logit)) </div><div class="t m0 x7f h1e y11b ffb fs6 fc1 sc0 ls0 ws0">#Forward selection AIC </div><div class="t m0 x7f h1e y11c ffb fs6 fc1 sc0 ls0 ws0">best.forward.AIC = step(empty.model,scope = list(lower = empty.model, upper = full.model),direction = </div><div class="t m0 x7f h1e y11d ffb fs6 fc1 sc0 ls0 ws0">&quot;forward&quot;, criterion = &quot;AIC&quot;, trace = FALSE) </div><div class="t m0 x7f h1e y11e ffb fs6 fc1 sc0 ls0 ws0">best.forward.AIC$formula #Status ~ TotalL + HumerusL + Wght + KeelL </div><div class="t m0 x7f h1e y11f ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y120 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y121 ffb fs6 fc1 sc0 ls0 ws0">#Forward selection BIC </div><div class="t m0 x7f h1e y122 ffb fs6 fc1 sc0 ls0 ws0">best.forward.BIC = step(empty.model,scope = list(lower = empty.model, upper = full.model),direction = </div><div class="t m0 x7f h1e y123 ffb fs6 fc1 sc0 ls0 ws0">&quot;forward&quot;, criterion = &quot;AIC&quot;, k =log(87) , trace = FALSE) </div><div class="t m0 x7f h1e y124 ffb fs6 fc1 sc0 ls0 ws0">best.forward.BIC$formula #Status ~ TotalL + HumerusL + Wght + KeelL </div><div class="t m0 x7f h1e y125 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y126 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y127 ffb fs6 fc1 sc0 ls0 ws0">setwd(&quot;~/Dropbox/0STA207/207 HW/207 Prj&quot;) </div><div class="t m0 x7f h1e y128 ffb fs6 fc1 sc0 ls0 ws0">library(openxlsx) </div><div class="t m0 x7f h1e y129 ffb fs6 fc1 sc0 ls0 ws0">library(corrplot) </div><div class="t m0 x7f h1e y12a ffb fs6 fc1 sc0 ls0 ws0">Data = read.xlsx(&quot;survival_sparrow.xlsx&quot;) </div><div class="t m0 x7f h1e y12b ffb fs6 fc1 sc0 ls0 ws0">names(Data)=c(&apos;Status&apos;,&apos;Age&apos;,&apos;TotalL&apos;,&apos;AlarExtL&apos;, </div><div class="t m0 x7f h1e y12c ffb fs6 fc1 sc0 ls0 ws0">              &apos;Wght&apos;,&apos;BeakHeadL&apos;,&apos;HumerusL&apos;, </div><div class="t m0 x7f h1e y12d ffb fs6 fc1 sc0 ls0 ws0">              &apos;FemurL&apos;,&apos;TribioTarsusL&apos;,&apos;SkullWd&apos;,&apos;KeelL&apos;) </div><div class="t m0 x7f h1e y12e ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y12f ffb fs6 fc1 sc0 ls0 ws0">Data[Data$Status==&apos;Perished&apos;,]$Status= 0 </div><div class="t m0 x7f h1e y130 ffb fs6 fc1 sc0 ls0 ws0">Data[Data$Status==&apos;Survived&apos;,]$Status = 1 </div><div class="t m0 x7f h1e y131 ffb fs6 fc1 sc0 ls0 ws0">Data$Status = factor(Data$Status) </div><div class="t m0 x7f h1e y132 ffb fs6 fc1 sc0 ls0 ws0">Data$Age  = factor(Data$Age ) </div><div class="t m0 x7f h1e y133 ffb fs6 fc1 sc0 ls0 ws0">Data$Wght = log(Data$Wght) </div><div class="t m0 x7f h1e y134 ffb fs6 fc1 sc0 ls0 ws0">Data$BeakHeadL= log(Data$BeakHeadL) </div><div class="t m0 x7f h1e y135 ffb fs6 fc1 sc0 ls0 ws0">#standarized quantitative variable variables </div><div class="t m0 x7f h1e y136 ffb fs6 fc1 sc0 ls0 ws0">for (i in 3:11){ </div><div class="t m0 x7f h1e y137 ffb fs6 fc1 sc0 ls0 ws0">  Data[,i] = (Data[,i]-mean(Data[,i]))/sd(Data[,i]) </div><div class="t m0 x7f h1e y138 ffb fs6 fc1 sc0 ls0 ws0">} </div><div class="t m0 x7f h1e y139 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y13a ffb fs6 fc1 sc0 ls0 ws0">###4 </div><div class="t m0 x7f h1e y13b ffb fs6 fc1 sc0 ls0 ws0">######################### </div><div class="t m0 x7f h1e y13c ffb fs6 fc1 sc0 ls0 ws0">#residual plot  </div><div class="t m0 x7f h1e y13d ffb fs6 fc1 sc0 ls0 ws0">logit.model = glm(Status ~ TotalL + Wght + HumerusL + KeelL, data =Data,family = </div><div class="t m0 x7f h1e y13e ffb fs6 fc1 sc0 ls0 ws0">binomial(link=logit),maxit = 100) </div><div class="t m0 x7f h1e y13f ffb fs6 fc1 sc0 ls0 ws0"> </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pff" class="pf w0 h0" data-page-no="f"><div class="pc pcf w0 h0"><div class="c x1 y1 w2 h2"><div class="t m0 x7f h1e yd2 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e yd3 ffb fs6 fc1 sc0 ls0 ws0">Resi_Plot(logit.model ) </div><div class="t m0 x7f h1e y10e ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y10f ffb fs6 fc1 sc0 ls0 ws0">library(LogisticDx) </div><div class="t m0 x7f h1e y110 ffb fs6 fc1 sc0 ls0 ws0">par(mfrow=c(1, 3)) </div><div class="t m0 x7f h1e y111 ffb fs6 fc1 sc0 ls0 ws0">good.stuff = dx(logit.model) </div><div class="t m0 x7f h1e y112 ffb fs6 fc1 sc0 ls0 ws0">df.beta = good.stuff$dBhat #DF Beta for removing each observation </div><div class="t m0 x7f h1e y113 ffb fs6 fc1 sc0 ls0 ws0">plot(df.beta) </div><div class="t m0 x7f h1e y114 ffb fs6 fc1 sc0 ls0 ws0">cutoff.beta = 0.5 </div><div class="t m0 x7f h1e y115 ffb fs6 fc1 sc0 ls0 ws0">df.beta[df.beta &gt; cutoff.beta]  </div><div class="t m0 x7f h1e y116 ffb fs6 fc1 sc0 ls0 ws0">good.stuff[df.beta &gt; cutoff.beta]  </div><div class="t m0 x7f h1e y117 ffb fs6 fc1 sc0 ls0 ws0">change.pearson = good.stuff$dChisq #Change in pearson X^2 for each observation </div><div class="t m0 x7f h1e y118 ffb fs6 fc1 sc0 ls0 ws0">plot(change.pearson) </div><div class="t m0 x7f h1e y119 ffb fs6 fc1 sc0 ls0 ws0">cutoff.pearson = 8 </div><div class="t m0 x7f h1e y11a ffb fs6 fc1 sc0 ls0 ws0">change.pearson[change.pearson &gt; cutoff.pearson] #Shows the values </div><div class="t m0 x7f h1e y11b ffb fs6 fc1 sc0 ls0 ws0">good.stuff[change.pearson &gt; cutoff.pearson,] #what observations they were </div><div class="t m0 x7f h1e y11c ffb fs6 fc1 sc0 ls0 ws0"># </div><div class="t m0 x7f h1e y11d ffb fs6 fc1 sc0 ls0 ws0">change.LR = good.stuff$dDev #Change in LR-test G^2 for each observation </div><div class="t m0 x7f h1e y11e ffb fs6 fc1 sc0 ls0 ws0">plot(change.LR) </div><div class="t m0 x7f h1e y11f ffb fs6 fc1 sc0 ls0 ws0">good.stuff[change.LR&gt; 4,] #what observations they were </div><div class="t m0 x7f h1e y120 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y121 ffb fs6 fc1 sc0 ls0 ws0">Data = Data[-27,] </div><div class="t m0 x7f h1e y122 ffb fs6 fc1 sc0 ls0 ws0">dim(Data) </div><div class="t m0 x7f h1e y123 ffb fs6 fc1 sc0 ls0 ws0">Data = Data[-75,] </div><div class="t m0 x7f h1e y124 ffb fs6 fc1 sc0 ls0 ws0">dim(Data) </div><div class="t m0 x7f h1e y125 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y126 ffb fs6 fc1 sc0 ls0 ws0">best.model = glm(Status ~ TotalL + Wght + HumerusL + KeelL, data =Data,family = </div><div class="t m0 x7f h1e y127 ffb fs6 fc1 sc0 ls0 ws0">binomial(link=logit),maxit = 100) </div><div class="t m0 x7f h1e y128 ffb fs6 fc1 sc0 ls0 ws0">##cross validation </div><div class="t m0 x7f h1e y129 ffb fs6 fc1 sc0 ls0 ws0">library(caret) </div><div class="t m0 x7f h1e y12a ffb fs6 fc1 sc0 ls0 ws0">ctrl &lt;- trainControl(method = &quot;repeatedcv&quot;, number = 5, savePredictions = TRUE) </div><div class="t m0 x7f h1e y12b ffb fs6 fc1 sc0 ls0 ws0">mod_fit &lt;- train(Status ~ TotalL + Wght + HumerusL + KeelL ,  data=Data[,-c(4,9)], method=&quot;glm&quot;, </div><div class="t m0 x7f h1e y12c ffb fs6 fc1 sc0 ls0 ws0">family=binomial(logit), </div><div class="t m0 x7f h1e y12d ffb fs6 fc1 sc0 ls0 ws0">                 trControl = ctrl, tuneLength = 5) </div><div class="t m0 x7f h1e y12e ffb fs6 fc1 sc0 ls0 ws0">mod_fit </div><div class="t m0 x7f h1e y12f ffb fs6 fc1 sc0 ls0 ws0">#r^2  </div><div class="t m0 x7f h1e y130 ffb fs6 fc1 sc0 ls0 ws0">r = cor(best.model$y,best.model$fitted.values) </div><div class="t m0 x7f h1e y131 ffb fs6 fc1 sc0 ls0 ws0">r </div><div class="t m0 x7f h1e y132 ffb fs6 fc1 sc0 ls0 ws0">prop.red = 1- sum((best.model$y -best.model$fitted.values)^2)/sum((best.model$y - </div><div class="t m0 x7f h1e y133 ffb fs6 fc1 sc0 ls0 ws0">mean(best.model$y))^2) </div><div class="t m0 x7f h1e y134 ffb fs6 fc1 sc0 ls0 ws0">prop.red </div><div class="t m0 x7f h1e y135 ffb fs6 fc1 sc0 ls0 ws0">#Classification tables, AUC, ROC. </div><div class="t m0 x7f h1e y136 ffb fs6 fc1 sc0 ls0 ws0">library(pROC) </div><div class="t m0 x7f h1e y137 ffb fs6 fc1 sc0 ls0 ws0">the.roc = roc(best.model$y, best.model$fitted.values,auc = TRUE, ci = TRUE,plot=TRUE, legacy.axes </div><div class="t m0 x7f h1e y138 ffb fs6 fc1 sc0 ls0 ws0">= TRUE) </div><div class="t m0 x7f h1e y139 ffb fs6 fc1 sc0 ls0 ws0">auc(the.roc) </div><div class="t m0 x7f h1e y13a ffb fs6 fc1 sc0 ls0 ws0">ci(the.roc) </div><div class="t m0 x7f h1e y13b ffb fs6 fc1 sc0 ls0 ws0">pi0 =0.50 </div><div class="t m0 x7f h1e y13c ffb fs6 fc1 sc0 ls0 ws0">my.table = table(truth = best.model$y,predict = ifelse(fitted(best.model)&gt;pi0,1,0)) </div><div class="t m0 x7f h1e y13d ffb fs6 fc1 sc0 ls0 ws0">my.table </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf10" class="pf w0 h0" data-page-no="10"><div class="pc pc10 w0 h0"><div class="c x1 y1 w2 h2"><div class="t m0 x7f h1e yd2 ffb fs6 fc1 sc0 ls0 ws0">#and the AUC, plot the ROC, and find a confidence interval for the AUC. It requires the actual values of </div><div class="t m0 x7f h1e yd3 ffb fs6 fc1 sc0 ls0 ws0">YY, the fitted values, and some arguments so that the AUC, and a confidence interval for the AUC are </div><div class="t m0 x7f h1e y10e ffb fs6 fc1 sc0 ls0 ws0">given back. </div><div class="t m0 x7f h1e y10f ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y110 ffb fs6 fc1 sc0 ls0 ws0">alpha = 0.05 </div><div class="t m0 x7f h1e y111 ffb fs6 fc1 sc0 ls0 ws0">round(confint(best.model,level = (1-alpha)),4) </div><div class="t m0 x7f h1e y112 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y113 ffb fs6 fc1 sc0 ls0 ws0">###5  </div><div class="t m0 x7f h1e y114 ffb fs6 fc1 sc0 ls0 ws0">######################### </div><div class="t m0 x7f h1e y115 ffb fs6 fc1 sc0 ls0 ws0">Data = read.xlsx(&quot;survival_sparrow.xlsx&quot;) </div><div class="t m0 x7f h1e y116 ffb fs6 fc1 sc0 ls0 ws0">names(Data)=c(&apos;Status&apos;,&apos;Age&apos;,&apos;TotalL&apos;,&apos;AlarExtL&apos;, </div><div class="t m0 x7f h1e y117 ffb fs6 fc1 sc0 ls0 ws0">              &apos;Wght&apos;,&apos;BeakHeadL&apos;,&apos;HumerusL&apos;, </div><div class="t m0 x7f h1e y118 ffb fs6 fc1 sc0 ls0 ws0">              &apos;FemurL&apos;,&apos;TribioTarsusL&apos;,&apos;SkullWd&apos;,&apos;KeelL&apos;) </div><div class="t m0 x7f h1e y119 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y11a ffb fs6 fc1 sc0 ls0 ws0"># Data processing </div><div class="t m0 x7f h1e y11b ffb fs6 fc1 sc0 ls0 ws0">Data[Data$Status==&apos;Perished&apos;,]$Status= 0 </div><div class="t m0 x7f h1e y11c ffb fs6 fc1 sc0 ls0 ws0">Data[Data$Status==&apos;Survived&apos;,]$Status = 1 </div><div class="t m0 x7f h1e y11d ffb fs6 fc1 sc0 ls0 ws0">Data$Status = factor(Data$Status) </div><div class="t m0 x7f h1e y11e ffb fs6 fc1 sc0 ls0 ws0">Data$Age  = factor(Data$Age ) </div><div class="t m0 x7f h1e y11f ffb fs6 fc1 sc0 ls0 ws0">Data$Wght = log(Data$Wght) </div><div class="t m0 x7f h1e y120 ffb fs6 fc1 sc0 ls0 ws0">Data$BeakHeadL= log(Data$BeakHeadL) </div><div class="t m0 x7f h1e y121 ffb fs6 fc1 sc0 ls0 ws0">#standarized quantitative variable variables </div><div class="t m0 x7f h1e y122 ffb fs6 fc1 sc0 ls0 ws0">for (i in 3:11){ </div><div class="t m0 x7f h1e y123 ffb fs6 fc1 sc0 ls0 ws0">  Data[,i] = (Data[,i]-mean(Data[,i]))/sd(Data[,i]) </div><div class="t m0 x7f h1e y124 ffb fs6 fc1 sc0 ls0 ws0">} </div><div class="t m0 x7f h1e y125 ffb fs6 fc1 sc0 ls0 ws0">logit.model = glm(Status ~ TotalL + Wght + HumerusL + KeelL + I(FemurL^2), data =Data,family = </div><div class="t m0 x7f h1e y126 ffb fs6 fc1 sc0 ls0 ws0">binomial(link=logit),maxit = 100) </div><div class="t m0 x7f h1e y127 ffb fs6 fc1 sc0 ls0 ws0">Resi_Plot(logit.model ) </div><div class="t m0 x7f h1e y128 ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y129 ffb fs6 fc1 sc0 ls0 ws0">library(LogisticDx) </div><div class="t m0 x7f h1e y12a ffb fs6 fc1 sc0 ls0 ws0">par(mfrow=c(1, 3)) </div><div class="t m0 x7f h1e y12b ffb fs6 fc1 sc0 ls0 ws0">good.stuff = dx(logit.model) </div><div class="t m0 x7f h1e y12c ffb fs6 fc1 sc0 ls0 ws0">df.beta = good.stuff$dBhat #DF Beta for removing each observation </div><div class="t m0 x7f h1e y12d ffb fs6 fc1 sc0 ls0 ws0">plot(df.beta) </div><div class="t m0 x7f h1e y12e ffb fs6 fc1 sc0 ls0 ws0">cutoff.beta = 0.9 </div><div class="t m0 x7f h1e y12f ffb fs6 fc1 sc0 ls0 ws0">df.beta[df.beta &gt; cutoff.beta]  </div><div class="t m0 x7f h1e y130 ffb fs6 fc1 sc0 ls0 ws0">good.stuff[df.beta &gt; cutoff.beta]  </div><div class="t m0 x7f h1e y131 ffb fs6 fc1 sc0 ls0 ws0">change.pearson = good.stuff$dChisq #Change in pearson X^2 for each observation </div><div class="t m0 x7f h1e y132 ffb fs6 fc1 sc0 ls0 ws0">plot(change.pearson) </div><div class="t m0 x7f h1e y133 ffb fs6 fc1 sc0 ls0 ws0">cutoff.pearson = 15 </div><div class="t m0 x7f h1e y134 ffb fs6 fc1 sc0 ls0 ws0">change.pearson[change.pearson &gt; cutoff.pearson] #Shows the values </div><div class="t m0 x7f h1e y135 ffb fs6 fc1 sc0 ls0 ws0">good.stuff[change.pearson &gt; cutoff.pearson,] #what observations they were </div><div class="t m0 x7f h1e y136 ffb fs6 fc1 sc0 ls0 ws0"># </div><div class="t m0 x7f h1e y137 ffb fs6 fc1 sc0 ls0 ws0">change.LR = good.stuff$dDev #Change in LR-test G^2 for each observation </div><div class="t m0 x7f h1e y138 ffb fs6 fc1 sc0 ls0 ws0">plot(change.LR) </div><div class="t m0 x7f h1e y139 ffb fs6 fc1 sc0 ls0 ws0">good.stuff[change.LR&gt; 6,] #what observations they were </div><div class="t m0 x7f h1e y13a ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y13b ffb fs6 fc1 sc0 ls0 ws0">#27 63 </div><div class="t m0 x7f h1e y13c ffb fs6 fc1 sc0 ls0 ws0">Data[27,] </div><div class="t m0 x7f h1e y13d ffb fs6 fc1 sc0 ls0 ws0">Data = Data[-27,] </div><div class="t m0 x7f h1e y13e ffb fs6 fc1 sc0 ls0 ws0">dim(Data) </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf11" class="pf w0 h0" data-page-no="11"><div class="pc pc11 w0 h0"><div class="c x1 y1 w2 h2"><div class="t m0 x7f h1e yd2 ffb fs6 fc1 sc0 ls0 ws0">best.model = glm(Status ~ TotalL + Wght + HumerusL + KeelL + I(FemurL^2), data =Data,family = </div><div class="t m0 x7f h1e yd3 ffb fs6 fc1 sc0 ls0 ws0">binomial(link=logit),maxit = 100) </div><div class="t m0 x7f h1e y10e ffb fs6 fc1 sc0 ls0 ws0">##cross validation </div><div class="t m0 x7f h1e y10f ffb fs6 fc1 sc0 ls0 ws0">library(caret) </div><div class="t m0 x7f h1e y110 ffb fs6 fc1 sc0 ls0 ws0">ctrl &lt;- trainControl(method = &quot;repeatedcv&quot;, number = 5, savePredictions = TRUE) </div><div class="t m0 x7f h1e y111 ffb fs6 fc1 sc0 ls0 ws0">mod_fit &lt;- train(Status ~TotalL + Wght + HumerusL + KeelL + I(FemurL^2) ,  data=Data[,-c(4,9)], </div><div class="t m0 x7f h1e y112 ffb fs6 fc1 sc0 ls0 ws0">method=&quot;glm&quot;, family=binomial(logit), </div><div class="t m0 x7f h1e y113 ffb fs6 fc1 sc0 ls0 ws0">                 trControl = ctrl, tuneLength = 5) </div><div class="t m0 x7f h1e y114 ffb fs6 fc1 sc0 ls0 ws0">mod_fit </div><div class="t m0 x7f h1e y115 ffb fs6 fc1 sc0 ls0 ws0">#r^2  </div><div class="t m0 x7f h1e y116 ffb fs6 fc1 sc0 ls0 ws0">r = cor(best.model$y,best.model$fitted.values) </div><div class="t m0 x7f h1e y117 ffb fs6 fc1 sc0 ls0 ws0">r </div><div class="t m0 x7f h1e y118 ffb fs6 fc1 sc0 ls0 ws0">prop.red = 1- sum((best.model$y -best.model$fitted.values)^2)/sum((best.model$y - </div><div class="t m0 x7f h1e y119 ffb fs6 fc1 sc0 ls0 ws0">mean(best.model$y))^2) </div><div class="t m0 x7f h1e y11a ffb fs6 fc1 sc0 ls0 ws0">prop.red </div><div class="t m0 x7f h1e y11b ffb fs6 fc1 sc0 ls0 ws0">#Classification tables, AUC, ROC. </div><div class="t m0 x7f h1e y11c ffb fs6 fc1 sc0 ls0 ws0">library(pROC) </div><div class="t m0 x7f h1e y11d ffb fs6 fc1 sc0 ls0 ws0">the.roc = roc(best.model$y, best.model$fitted.values,auc = TRUE, ci = TRUE,plot=TRUE, legacy.axes </div><div class="t m0 x7f h1e y11e ffb fs6 fc1 sc0 ls0 ws0">= TRUE) </div><div class="t m0 x7f h1e y11f ffb fs6 fc1 sc0 ls0 ws0">auc(the.roc) </div><div class="t m0 x7f h1e y120 ffb fs6 fc1 sc0 ls0 ws0">ci(the.roc) </div><div class="t m0 x7f h1e y121 ffb fs6 fc1 sc0 ls0 ws0">pi0 =0.50 </div><div class="t m0 x7f h1e y122 ffb fs6 fc1 sc0 ls0 ws0">my.table = table(truth = best.model$y,predict = ifelse(fitted(best.model)&gt;pi0,1,0)) </div><div class="t m0 x7f h1e y123 ffb fs6 fc1 sc0 ls0 ws0">my.table </div><div class="t m0 x7f h1e y124 ffb fs6 fc1 sc0 ls0 ws0">#and the AUC, plot the ROC, and find a confidence interval for the AUC. It requires the actual values of </div><div class="t m0 x7f h1e y125 ffb fs6 fc1 sc0 ls0 ws0">YY, the fitted values, and some arguments so that the AUC, and a confidence interval for the AUC are </div><div class="t m0 x7f h1e y126 ffb fs6 fc1 sc0 ls0 ws0">given back. </div><div class="t m0 x7f h1e y127 ffb fs6 fc1 sc0 ls0 ws0">Resi_Plot(best.model) </div><div class="t m0 x7f h1e y128 ffb fs6 fc1 sc0 ls0 ws0">alpha = 0.05 </div><div class="t m0 x7f h1e y129 ffb fs6 fc1 sc0 ls0 ws0">round(confint(best.model,level = (1-alpha)),4) </div><div class="t m0 x7f h1e y12a ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y12b ffb fs6 fc1 sc0 ls0 ws0">exp(summary(best.model)$coefficients[,1]) </div><div class="t m0 x7f h1e y12c ffb fs6 fc1 sc0 ls0 ws0"> </div><div class="t m0 x7f h1e y12d ffb fs6 fc1 sc0 ls0 ws0">Resi_Plot = function(logit.model){ </div><div class="t m0 x7f h1e y12e ffb fs6 fc1 sc0 ls0 ws0">  par(mfrow=c(2, 2)) </div><div class="t m0 x7f h1e y12f ffb fs6 fc1 sc0 ls0 ws0">  plot(fitted(logit.model), </div><div class="t m0 x7f h1e y130 ffb fs6 fc1 sc0 ls0 ws0">       resid(logit.model, type=&apos;pearson&apos;)/sqrt(1 - hatvalues(logit.model)), </div><div class="t m0 x7f h1e y131 ffb fs6 fc1 sc0 ls0 ws0">       main = &apos;student pearson&apos;, ylab = &apos;student peason&apos;,xlab = &apos;fitted prob&apos;) </div><div class="t m0 x7f h1e y132 ffb fs6 fc1 sc0 ls0 ws0">  lines(lowess(data.frame(fitted(logit.model), </div><div class="t m0 x7f h1e y133 ffb fs6 fc1 sc0 ls0 ws0">                          resid(logit.model, type=&apos;pearson&apos;)/sqrt(1 - hatvalues(logit.model)))), col = 2) </div><div class="t m0 x7f h1e y134 ffb fs6 fc1 sc0 ls0 ws0">  plot(fitted(logit.model), </div><div class="t m0 x7f h1e y135 ffb fs6 fc1 sc0 ls0 ws0">       resid(logit.model, type=&apos;pearson&apos;), </div><div class="t m0 x7f h1e y136 ffb fs6 fc1 sc0 ls0 ws0">       main = &apos;pearson&apos;, ylab = &apos;peason&apos;,xlab = &apos;fitted prob&apos;) </div><div class="t m0 x7f h1e y137 ffb fs6 fc1 sc0 ls0 ws0">  lines(lowess(data.frame(fitted(logit.model), </div><div class="t m0 x7f h1e y138 ffb fs6 fc1 sc0 ls0 ws0">                          resid(logit.model, type=&apos;pearson&apos;))), col = 2) </div><div class="t m0 x7f h1e y139 ffb fs6 fc1 sc0 ls0 ws0">  plot(fitted(logit.model),resid(logit.model), </div><div class="t m0 x7f h1e y13a ffb fs6 fc1 sc0 ls0 ws0">       main = &apos;deviance&apos;, ylab = &apos;deviance&apos;,xlab = &apos;fitted prob&apos;) </div><div class="t m0 x7f h1e y13b ffb fs6 fc1 sc0 ls0 ws0">  lines(lowess(data.frame(fitted(logit.model), </div><div class="t m0 x7f h1e y13c ffb fs6 fc1 sc0 ls0 ws0">                          resid(logit.model, type=&apos;deviance&apos;))), col = 2) </div><div class="t m0 x7f h1e y13d ffb fs6 fc1 sc0 ls0 ws0">  library(faraway) </div><div class="t m0 x7f h1e y13e ffb fs6 fc1 sc0 ls0 ws0">  faraway::halfnorm( resid(logit.model,&apos;pearson&apos;) ,main = &apos;half Normal&apos;) </div><div class="t m0 x7f h1e y13f ffb fs6 fc1 sc0 ls0 ws0">} </div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
</div>
<div class="loading-indicator">

</div>
</body>
</html>
